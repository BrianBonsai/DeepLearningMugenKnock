{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "HRED_pytorch_sand.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yoyoyo-yo/DeepLearningMugenKnock/blob/master/pytorch/HRED_pytorch_sand.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0H8bE7gkhEV",
        "colab_type": "text"
      },
      "source": [
        "# HRED\n",
        "\n",
        "元論文 : Attention if All You Need https://arxiv.org/abs/1706.03762 (2017)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIRpEHgCkoE0",
        "colab_type": "code",
        "outputId": "fa5f3c88-3e5f-4cdd-90f9-5b90f55302c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "!pip install numpy matplotlib opencv-python torch torchvision torchsummary pandas easydict"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.18.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.2.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.5.0+cu101)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.6.0+cu101)\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.6/dist-packages (1.5.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (1.0.4)\n",
            "Requirement already satisfied: easydict in /usr/local/lib/python3.6/dist-packages (1.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.8.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch) (0.16.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (7.0.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ab___Yzwk1hq",
        "colab_type": "text"
      },
      "source": [
        "# Ginza"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjvQdntDk3ls",
        "colab_type": "code",
        "outputId": "1446af74-6e65-4992-9f37-7415fabfa8af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 870
        }
      },
      "source": [
        "!pip install ginza"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ginza\n",
            "  Downloading https://files.pythonhosted.org/packages/93/43/43818861210c71a0a9f789e7350b785ba60bad38196745c2f8e88271dfa8/ginza-3.1.2.tar.gz\n",
            "Requirement already satisfied: spacy>=2.2.3 in /usr/local/lib/python3.6/dist-packages (from ginza) (2.2.4)\n",
            "Collecting ja_ginza<3.2.0,>=3.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/02/ad08f43df50c5d877a7b2dcd56f4ebf33a5818b517550516e8ba059069fa/ja_ginza-3.1.0.tar.gz (54.9MB)\n",
            "\u001b[K     |████████████████████████████████| 54.9MB 56kB/s \n",
            "\u001b[?25hCollecting SudachiPy>=0.4.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c1/c2/891aee144e98bbfe331f02558d5b3608731ca70926657cbe9e80737b57d5/SudachiPy-0.4.5-py3-none-any.whl (74kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 6.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.3->ginza) (2.0.3)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.3->ginza) (1.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.3->ginza) (47.1.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.3->ginza) (1.0.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.3->ginza) (3.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.3->ginza) (0.6.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.3->ginza) (1.0.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.3->ginza) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.3->ginza) (1.18.4)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.3->ginza) (0.4.1)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.3->ginza) (7.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.3->ginza) (4.41.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.3->ginza) (1.0.2)\n",
            "Collecting ja_ginza_dict<3.2.0,>=3.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e8/e5/c4ea3f165acb38fa125e992d1a6fcfb9a5a8ab6a14cc5010c836713c386b/ja_ginza_dict-3.1.0-1.tar.gz (44.8MB)\n",
            "\u001b[K     |████████████████████████████████| 44.8MB 73kB/s \n",
            "\u001b[?25hRequirement already satisfied: sortedcontainers~=2.1.0 in /usr/local/lib/python3.6/dist-packages (from SudachiPy>=0.4.2->ginza) (2.1.0)\n",
            "Collecting dartsclone~=0.9.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6d/34/987a076369ed086ee953e2f0b9ab5ff3e1a682ba4f781678ac5648144896/dartsclone-0.9.0-cp36-cp36m-manylinux1_x86_64.whl (474kB)\n",
            "\u001b[K     |████████████████████████████████| 481kB 40.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.3->ginza) (1.6.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.3->ginza) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.3->ginza) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.3->ginza) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.3->ginza) (3.0.4)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.6/dist-packages (from dartsclone~=0.9.0->SudachiPy>=0.4.2->ginza) (0.29.19)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.3->ginza) (3.1.0)\n",
            "Building wheels for collected packages: ginza, ja-ginza, ja-ginza-dict\n",
            "  Building wheel for ginza (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ginza: filename=ginza-3.1.2-cp36-none-any.whl size=17311 sha256=9c643d512cc66a38ae743a48ea355912b23bb8d53289a81271152a1a319338b8\n",
            "  Stored in directory: /root/.cache/pip/wheels/70/8d/57/f089078acc0dbaebffc08c178e9f20924fa794c114ad36f7f7\n",
            "  Building wheel for ja-ginza (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ja-ginza: filename=ja_ginza-3.1.0-cp36-none-any.whl size=54963619 sha256=c1d796ee7b46ea198c9b2423e0df87ae8e8b94851741d4dabd568c5344fa4c67\n",
            "  Stored in directory: /root/.cache/pip/wheels/f2/8a/07/1837eeb5c5648fa8d266102b78a894e495234585ac3f024cf1\n",
            "  Building wheel for ja-ginza-dict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ja-ginza-dict: filename=ja_ginza_dict-3.1.0-cp36-none-any.whl size=70877544 sha256=73105c8bae77a5853ab0aba996aa68484b2f3747c2ff2955467ba15c6df95e7f\n",
            "  Stored in directory: /root/.cache/pip/wheels/30/88/d7/7f0692ba26060966af34538e1079438d16640c54e04a15a76a\n",
            "Successfully built ginza ja-ginza ja-ginza-dict\n",
            "Installing collected packages: ja-ginza-dict, ja-ginza, dartsclone, SudachiPy, ginza\n",
            "Successfully installed SudachiPy-0.4.5 dartsclone-0.9.0 ginza-3.1.2 ja-ginza-3.1.0 ja-ginza-dict-3.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjGBSMOxk7sS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pkg_resources, imp\n",
        "imp.reload(pkg_resources)\n",
        "\n",
        "import spacy\n",
        "nlp = spacy.load('ja_ginza')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEn0fNCVk98x",
        "colab_type": "code",
        "outputId": "f24fe42a-7c43-4df7-fd91-417a7c761be0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "# test\n",
        "import spacy\n",
        "\n",
        "nlp = spacy.load('ja_ginza')\n",
        "doc = nlp('あのラーメン屋にはよく行く。美味しいんだ。')\n",
        "\n",
        "for sent in doc.sents:\n",
        "    for token in sent:\n",
        "        info = [\n",
        "            token.i,         # トークン番号\n",
        "            token.orth_,     # テキスト\n",
        "            #token._.reading, # 読みカナ\n",
        "            token.lemma_,    # 基本形\n",
        "            token.pos_,      # 品詞\n",
        "            token.tag_,      # 品詞詳細\n",
        "            #token._.inf      # 活用情報\n",
        "        ]\n",
        "        print(info)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 'あの', 'アノ', '彼の', 'DET', '連体詞', '*,*']\n",
            "[1, 'ラーメン', 'ラーメン', 'ラーメン', 'NOUN', '名詞-普通名詞-一般', '*,*']\n",
            "[2, '屋', 'ヤ', '屋', 'NOUN', '接尾辞-名詞的-一般', '*,*']\n",
            "[3, 'に', 'ニ', 'に', 'ADP', '助詞-格助詞', '*,*']\n",
            "[4, 'は', 'ハ', 'は', 'ADP', '助詞-係助詞', '*,*']\n",
            "[5, 'よく', 'ヨク', '良く', 'ADV', '副詞', '*,*']\n",
            "[6, '行く', 'イク', '行く', 'VERB', '動詞-非自立可能', '五段-カ行,終止形-一般']\n",
            "[7, '。', '。', '。', 'PUNCT', '補助記号-句点', '*,*']\n",
            "[8, '美味しい', 'オイシイ', '美味しい', 'ADJ', '形容詞-一般', '形容詞,連体形-一般']\n",
            "[9, 'ん', 'ン', 'の', 'SCONJ', '助詞-準体助詞', '*,*']\n",
            "[10, 'だ', 'ダ', 'だ', 'AUX', '助動詞', '助動詞-ダ,終止形-一般']\n",
            "[11, '。', '。', '。', 'PUNCT', '補助記号-句点', '*,*']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6j-kiToPUyo",
        "colab_type": "text"
      },
      "source": [
        "# Download dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NnIwttOjHJe",
        "colab_type": "code",
        "outputId": "e30ed82a-27c4-4cb4-ea17-992e8707e1c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rFAds04jPnt",
        "colab_type": "code",
        "outputId": "f89e172b-0cf0-44ab-f055-35692d6e2f0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "from glob import glob\n",
        "\n",
        "glob('/content/drive/My Drive/Colab Notebooks/datasets/sandwitchman/*_original.txt')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/My Drive/Colab Notebooks/datasets/sandwitchman/sandwitchman_hanayome_original.txt',\n",
              " '/content/drive/My Drive/Colab Notebooks/datasets/sandwitchman/sandwitchman_gasorin_original.txt',\n",
              " '/content/drive/My Drive/Colab Notebooks/datasets/sandwitchman/sandwitchman_sougiya_original.txt',\n",
              " '/content/drive/My Drive/Colab Notebooks/datasets/sandwitchman/sandwitchman_sanpo_original.txt',\n",
              " '/content/drive/My Drive/Colab Notebooks/datasets/sandwitchman/sandwitchman_ijime_original.txt',\n",
              " '/content/drive/My Drive/Colab Notebooks/datasets/sandwitchman/sandwitchman_syokumushitsumon_original.txt',\n",
              " '/content/drive/My Drive/Colab Notebooks/datasets/sandwitchman/sandwitchman_momotaro_original.txt',\n",
              " '/content/drive/My Drive/Colab Notebooks/datasets/sandwitchman/sandwitchman_ryokou_original.txt',\n",
              " '/content/drive/My Drive/Colab Notebooks/datasets/sandwitchman/sandwitchman_anpanman_original.txt',\n",
              " '/content/drive/My Drive/Colab Notebooks/datasets/sandwitchman/sandwitchman_keisatsu_original.txt',\n",
              " '/content/drive/My Drive/Colab Notebooks/datasets/sandwitchman/sandwitchman_speech_original.txt',\n",
              " '/content/drive/My Drive/Colab Notebooks/datasets/sandwitchman/sandwitchman_soushiki_original.txt']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awXNxB6-jPqy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_corpus(fname):\n",
        "    corpus = []\n",
        "\n",
        "    with open(fname, 'r') as f:\n",
        "        for line in f.readlines():\n",
        "            line = line.rstrip()\n",
        "            _corpus = []\n",
        "            for sent in nlp(line).sents:\n",
        "                for token in sent:\n",
        "                    _corpus.append(token.orth_)\n",
        "\n",
        "            corpus = list(set(corpus) | set(_corpus))\n",
        "    corpus.sort()\n",
        "    return corpus"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owHqIBMyjPt-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sample\n",
        "corpus = get_corpus('/content/drive/My Drive/Colab Notebooks/datasets/sandwitchman/sandwitchman_hanayome_original.txt')\n",
        "corpus = ['<UNKNOWN>'] + corpus"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPdw6l74tYMW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_data(fname, corpus):\n",
        "    Xs = []\n",
        "    with open(fname, 'r') as f:\n",
        "        for line in f.readlines():\n",
        "            line = line.rstrip()\n",
        "            _Xs = [corpus.index('<SOS>')]\n",
        "            for sent in nlp(line).sents:\n",
        "                for token in sent:\n",
        "                    w = token.orth_\n",
        "\n",
        "                    if w in corpus:\n",
        "                        ind = corpus.index(w)\n",
        "                    else:\n",
        "                        ind = corpus.index('<UNKNOWN>')\n",
        "                    _Xs.append(ind)\n",
        "            _Xs.append(corpus.index('<EOS>'))\n",
        "            Xs.append(_Xs)\n",
        "\n",
        "    return Xs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJ-z54NTvcvV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_data(data, data_n=None):\n",
        "    data_n = len(data) if data_n is None else data_n\n",
        "    Xs = []\n",
        "    for i in range(0, len(data) - data_n):\n",
        "        _Xs = []\n",
        "        for j in range(data_n):\n",
        "            _Xs.append(data[i + j])\n",
        "        Xs.append(_Xs)\n",
        "    return Xs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HY1gx9FduRvu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sample\n",
        "# data = read_data('/content/drive/My Drive/Colab Notebooks/datasets/sandwitchman/sandwitchman_hanayome_original.txt', corpus)\n",
        "# get_data(data, data_n=HRED_SESSION)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sjoKf_PPQdl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get corpus\n",
        "corpus = ['<SOS>', '<EOS>', '<UNKNOWN>']\n",
        "for fpath in glob('/content/drive/My Drive/Colab Notebooks/datasets/sandwitchman/*_original.txt'):\n",
        "    _corpus = get_corpus(fpath)\n",
        "    corpus = list(set(corpus) | set(_corpus))\n",
        "\n",
        "corpus.sort()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9i2CqZ0vTQe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get training data\n",
        "data_Xs = []\n",
        "\n",
        "HRED_SESSION = 5\n",
        "\n",
        "for fpath in glob('/content/drive/My Drive/Colab Notebooks/datasets/sandwitchman/*_original.txt'):\n",
        "    data = read_data(fpath, corpus)\n",
        "    _data_Xs = get_data(data, data_n=5)\n",
        "    data_Xs += _data_Xs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZ64UhTzkhEW",
        "colab_type": "text"
      },
      "source": [
        "# Import and Config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JWBAlBskhEX",
        "colab_type": "code",
        "outputId": "f50c17d9-6817-4d21-cee9-2e1997063604",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import os\n",
        "import argparse\n",
        "from pprint import pprint\n",
        "\n",
        "import numpy as np\n",
        "from collections import OrderedDict\n",
        "from easydict import EasyDict\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchsummary import summary\n",
        "\n",
        "\n",
        "#---\n",
        "# config\n",
        "#---\n",
        "cfg = EasyDict()\n",
        "\n",
        "cfg.CORPUS1_NUM = len(corpus)\n",
        "cfg.CORPUS2_NUM =  len(corpus)\n",
        "\n",
        "# Seq2seq config\n",
        "cfg.SEQ2SEQ_MAX_LENGTH = 1000 # decoder max output length\n",
        "cfg.SEQ2SEQ_TRAIN_FORCE_PROB = 0.5 # train input is forced to gt with this probability\n",
        "cfg.SEQ2SEQ_NEXT_WORD_SELECTION = 'prob' # prob, argmax\n",
        "cfg.SEQ2SEQ_RNN_DIM = 512\n",
        "cfg.SEQ2SEQ_USE_RNN_BD = True # use bidirectional RNN\n",
        "\n",
        "cfg.SEQ2SEQ_E_ATTENTION = False\n",
        "cfg.SEQ2SEQ_E_ATTENTION_TIME = 2  # Hopping if > 1\n",
        "cfg.SEQ2SEQ_E_DIM = 64\n",
        "cfg.SEQ2SEQ_E_ATTENTION_DIM = 64\n",
        "cfg.SEQ2SEQ_E_DROPOUT = 0.2\n",
        "cfg.SEQ2SEQ_E_USE_SELF_ATTENTION = True # self attention of Encoder\n",
        "cfg.SEQ2SEQ_E_USE_SOURCE_TARGET_ATTENTION = True # use source target attention\n",
        "cfg.SEQ2SEQ_E_MULTIHEAD_ATTENTION_N = 8 # Multi head attention\n",
        "cfg.SEQ2SEQ_E_USE_FFN = True # Feed forward network\n",
        "cfg.SEQ2SEQ_E_FFN_DIM = 512\n",
        "cfg.SEQ2SEQ_E_USE_PE = True # Positional encoding\n",
        "\n",
        "cfg.SEQ2SEQ_D_ATTENTION = False\n",
        "cfg.SEQ2SEQ_D_ATTENTION_TIME = 2  # Hopping if > 1\n",
        "cfg.SEQ2SEQ_D_DIM = 64\n",
        "cfg.SEQ2SEQ_D_ATTENTION_DIM = 64\n",
        "cfg.SEQ2SEQ_D_DROPOUT = 0.2\n",
        "cfg.SEQ2SEQ_D_USE_SELF_ATTENTIION = True # self attention of Decoder\n",
        "cfg.SEQ2SEQ_D_USE_SOURCE_TARGET_ATTENTION = True # use source target attention\n",
        "cfg.SEQ2SEQ_D_MULTIHEAD_ATTENTION_N = 8 # Multi head attention\n",
        "cfg.SEQ2SEQ_D_USE_FFN = True # Feed forward network\n",
        "cfg.SEQ2SEQ_D_FFN_DIM = 512\n",
        "cfg.SEQ2SEQ_D_USE_PE = True # Positional encoding\n",
        "\n",
        "cfg.HRED_HIDDEN_DIM = 512 # d_s in original paper\n",
        "\n",
        "cfg.CHANNEL_AXIS = 1 # 1 ... [mb, c, h, w], 3 ... [mb, h, w, c]\n",
        "\n",
        "cfg.GPU = True\n",
        "cfg.DEVICE_TYPE = 'cuda' if cfg.GPU and torch.cuda.is_available() else 'cpu'\n",
        "cfg.DEVICE = torch.device(cfg.DEVICE_TYPE)\n",
        "\n",
        "# train\n",
        "cfg.TRAIN = EasyDict()\n",
        "cfg.TRAIN.DISPAY_ITERATION_INTERVAL = 50\n",
        "\n",
        "cfg.PREFIX = 'Seq2seq-Attention'\n",
        "cfg.TRAIN.MODEL_E_SAVE_PATH = 'models/' + cfg.PREFIX + '_E_{}.pt'\n",
        "cfg.TRAIN.MODEL_D_SAVE_PATH = 'models/' + cfg.PREFIX + '_D_{}.pt'\n",
        "cfg.TRAIN.MODEL_SAVE_INTERVAL = 200\n",
        "cfg.TRAIN.ITERATION = 10_000\n",
        "cfg.TRAIN.MINIBATCH = 1\n",
        "cfg.TRAIN.OPTIMIZER_E = torch.optim.Adam\n",
        "cfg.TRAIN.LEARNING_PARAMS_E = {'lr' : 0.01, 'betas' : (0., 0.9)}\n",
        "cfg.TRAIN.OPTIMIZER_D = torch.optim.Adam\n",
        "cfg.TRAIN.LEARNING_PARAMS_D = {'lr' : 0.01, 'betas' : (0., 0.9)}\n",
        "cfg.TRAIN.OPTIMIZER_H = torch.optim.Adam\n",
        "cfg.TRAIN.LEARNING_PARAMS_H = {'lr' : 0.01, 'betas' : (0., 0.9)}\n",
        "cfg.TRAIN.LOSS_FUNCTION = torch.nn.NLLLoss()\n",
        "\n",
        "cfg.TRAIN.DATA_PATH = '/content/drive/My Drive/Colab Notebooks/Dataset/train/images/'\n",
        "cfg.TRAIN.DATA_HORIZONTAL_FLIP = True # data augmentation : holizontal flip\n",
        "cfg.TRAIN.DATA_VERTICAL_FLIP = True # data augmentation : vertical flip\n",
        "cfg.TRAIN.DATA_ROTATION = 1 # data augmentation : rotation False, or integer\n",
        "\n",
        "cfg.TRAIN.LEARNING_PROCESS_RESULT_SAVE = True\n",
        "cfg.TRAIN.LEARNING_PROCESS_RESULT_INTERVAL = 200\n",
        "cfg.TRAIN.LEARNING_PROCESS_RESULT_IMAGE_PATH = 'result/' + cfg.PREFIX + '_result_{}.jpg'\n",
        "cfg.TRAIN.LEARNING_PROCESS_RESULT_LOSS_PATH = 'result/' + cfg.PREFIX + '_loss.txt'\n",
        "\n",
        "\n",
        "# test\n",
        "cfg.TEST = EasyDict()\n",
        "cfg.TEST.MODEL_E_PATH = cfg.TRAIN.MODEL_E_SAVE_PATH.format('final')\n",
        "cfg.TEST.MODEL_D_PATH = cfg.TRAIN.MODEL_D_SAVE_PATH.format('final')\n",
        "cfg.TEST.DATA_PATH = '/content/drive/My Drive/Colab Notebooks/Dataset/test/images/'\n",
        "cfg.TEST.MINIBATCH = 10\n",
        "cfg.TEST.ITERATION = 2\n",
        "cfg.TEST.RESULT_SAVE = False\n",
        "cfg.TEST.RESULT_IMAGE_PATH = 'result/' + cfg.PREFIX + '_result_{}.jpg'\n",
        "\n",
        "# random seed\n",
        "torch.manual_seed(0)\n",
        "\n",
        "\n",
        "# make model save directory\n",
        "def make_dir(path):\n",
        "    if '/' in path:\n",
        "        model_save_dir = '/'.join(path.split('/')[:-1])\n",
        "        os.makedirs(model_save_dir, exist_ok=True)\n",
        "\n",
        "make_dir(cfg.TRAIN.MODEL_D_SAVE_PATH)\n",
        "make_dir(cfg.TRAIN.LEARNING_PROCESS_RESULT_IMAGE_PATH)\n",
        "make_dir(cfg.TRAIN.LEARNING_PROCESS_RESULT_LOSS_PATH)\n",
        "\n",
        "pprint(cfg)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'CHANNEL_AXIS': 1,\n",
            " 'CORPUS1_NUM': 2153,\n",
            " 'CORPUS2_NUM': 2153,\n",
            " 'DEVICE': device(type='cuda'),\n",
            " 'DEVICE_TYPE': 'cuda',\n",
            " 'GPU': True,\n",
            " 'HRED_HIDDEN_DIM': 512,\n",
            " 'PREFIX': 'Seq2seq-Attention',\n",
            " 'SEQ2SEQ_D_ATTENTION': False,\n",
            " 'SEQ2SEQ_D_ATTENTION_DIM': 64,\n",
            " 'SEQ2SEQ_D_ATTENTION_TIME': 2,\n",
            " 'SEQ2SEQ_D_DIM': 64,\n",
            " 'SEQ2SEQ_D_DROPOUT': 0.2,\n",
            " 'SEQ2SEQ_D_FFN_DIM': 512,\n",
            " 'SEQ2SEQ_D_MULTIHEAD_ATTENTION_N': 8,\n",
            " 'SEQ2SEQ_D_USE_FFN': True,\n",
            " 'SEQ2SEQ_D_USE_PE': True,\n",
            " 'SEQ2SEQ_D_USE_SELF_ATTENTIION': True,\n",
            " 'SEQ2SEQ_D_USE_SOURCE_TARGET_ATTENTION': True,\n",
            " 'SEQ2SEQ_E_ATTENTION': False,\n",
            " 'SEQ2SEQ_E_ATTENTION_DIM': 64,\n",
            " 'SEQ2SEQ_E_ATTENTION_TIME': 2,\n",
            " 'SEQ2SEQ_E_DIM': 64,\n",
            " 'SEQ2SEQ_E_DROPOUT': 0.2,\n",
            " 'SEQ2SEQ_E_FFN_DIM': 512,\n",
            " 'SEQ2SEQ_E_MULTIHEAD_ATTENTION_N': 8,\n",
            " 'SEQ2SEQ_E_USE_FFN': True,\n",
            " 'SEQ2SEQ_E_USE_PE': True,\n",
            " 'SEQ2SEQ_E_USE_SELF_ATTENTION': True,\n",
            " 'SEQ2SEQ_E_USE_SOURCE_TARGET_ATTENTION': True,\n",
            " 'SEQ2SEQ_MAX_LENGTH': 1000,\n",
            " 'SEQ2SEQ_NEXT_WORD_SELECTION': 'prob',\n",
            " 'SEQ2SEQ_RNN_DIM': 512,\n",
            " 'SEQ2SEQ_TRAIN_FORCE_PROB': 0.5,\n",
            " 'SEQ2SEQ_USE_RNN_BD': True,\n",
            " 'TEST': {'DATA_PATH': '/content/drive/My Drive/Colab '\n",
            "                       'Notebooks/Dataset/test/images/',\n",
            "          'ITERATION': 2,\n",
            "          'MINIBATCH': 10,\n",
            "          'MODEL_D_PATH': 'models/Seq2seq-Attention_D_final.pt',\n",
            "          'MODEL_E_PATH': 'models/Seq2seq-Attention_E_final.pt',\n",
            "          'RESULT_IMAGE_PATH': 'result/Seq2seq-Attention_result_{}.jpg',\n",
            "          'RESULT_SAVE': False},\n",
            " 'TRAIN': {'DATA_HORIZONTAL_FLIP': True,\n",
            "           'DATA_PATH': '/content/drive/My Drive/Colab '\n",
            "                        'Notebooks/Dataset/train/images/',\n",
            "           'DATA_ROTATION': 1,\n",
            "           'DATA_VERTICAL_FLIP': True,\n",
            "           'DISPAY_ITERATION_INTERVAL': 50,\n",
            "           'ITERATION': 10000,\n",
            "           'LEARNING_PARAMS_D': {'betas': [0.0, 0.9], 'lr': 0.01},\n",
            "           'LEARNING_PARAMS_E': {'betas': [0.0, 0.9], 'lr': 0.01},\n",
            "           'LEARNING_PARAMS_H': {'betas': [0.0, 0.9], 'lr': 0.01},\n",
            "           'LEARNING_PROCESS_RESULT_IMAGE_PATH': 'result/Seq2seq-Attention_result_{}.jpg',\n",
            "           'LEARNING_PROCESS_RESULT_INTERVAL': 200,\n",
            "           'LEARNING_PROCESS_RESULT_LOSS_PATH': 'result/Seq2seq-Attention_loss.txt',\n",
            "           'LEARNING_PROCESS_RESULT_SAVE': True,\n",
            "           'LOSS_FUNCTION': NLLLoss(),\n",
            "           'MINIBATCH': 1,\n",
            "           'MODEL_D_SAVE_PATH': 'models/Seq2seq-Attention_D_{}.pt',\n",
            "           'MODEL_E_SAVE_PATH': 'models/Seq2seq-Attention_E_{}.pt',\n",
            "           'MODEL_SAVE_INTERVAL': 200,\n",
            "           'OPTIMIZER_D': <class 'torch.optim.adam.Adam'>,\n",
            "           'OPTIMIZER_E': <class 'torch.optim.adam.Adam'>,\n",
            "           'OPTIMIZER_H': <class 'torch.optim.adam.Adam'>}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfhZkkxckhEZ",
        "colab_type": "text"
      },
      "source": [
        "# Define Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHSZpaajkhEa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Reshape(torch.nn.Module):\n",
        "    def __init__(self, shape):\n",
        "        super(Reshape, self).__init__()\n",
        "        self.shape = shape\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return x.reshape(self.shape)\n",
        "\n",
        "class Permute(torch.nn.Module):\n",
        "    def __init__(self, *args):\n",
        "        super(Permute, self).__init__()\n",
        "        self.shape = args\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return x.permute(self.shape)\n",
        "\n",
        "\n",
        "class Encoder(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim=64, rnn_dim=64, rnn_hidden_size=1, attention_dim=64, max_length=100, \n",
        "        dropout_p=0.1, attention_time=1, use_source_target_attention=False,\n",
        "        use_self_attention=False, multiHead_attention_num=1, use_FFN=False, FFN_dim=2048, use_PE=False, use_bd=False):\n",
        "    \n",
        "        super(Encoder, self).__init__()\n",
        "        self.max_length = max_length\n",
        "        self.rnn_dim = rnn_dim\n",
        "        self.rnn_hidden_size = rnn_hidden_size\n",
        "\n",
        "        # Embedding\n",
        "        self.embedding = torch.nn.Embedding(input_dim, hidden_dim)\n",
        "\n",
        "        # Positional Encoding\n",
        "        if use_PE:\n",
        "            self.pe = PE()\n",
        "\n",
        "        # Attention\n",
        "        self.attentions = []\n",
        "        if attention_time > 0:\n",
        "            for i in range(attention_time):\n",
        "                # Self Attention\n",
        "                if use_self_attention:\n",
        "                    self.attentions.append(Attention(\n",
        "                        hidden_dim=hidden_dim, memory_dim=hidden_dim, attention_dim=attention_dim, output_dim=hidden_dim,\n",
        "                        dropout_p=dropout_p, max_length=max_length, self_attention=use_self_attention, head_num=multiHead_attention_num))\n",
        "\n",
        "                # Feed Forward Network\n",
        "                if use_FFN:\n",
        "                    self.attentions.append(FFN(dim=FFN_dim, d_model=hidden_dim, dropout_p=dropout_p))\n",
        "\n",
        "        self.attentions = torch.nn.ModuleList(self.attentions)\n",
        "\n",
        "        # output GRU\n",
        "        self.gru = torch.nn.GRU(hidden_dim, rnn_dim, bidirectional=use_bd)\n",
        "\n",
        "\n",
        "    def forward(self, x, hidden, x_memory):\n",
        "        # Embedding\n",
        "        x = self.embedding(x).view(1, 1, -1)\n",
        "        x_memory = self.embedding(x_memory).permute(1, 0, 2)\n",
        "        x_memory = x_memory.float()\n",
        "\n",
        "        # Positional Encoding\n",
        "        if hasattr(self, 'PE'):\n",
        "            x = self.pe(x)\n",
        "            x_memory = self.pe(x_memory)\n",
        "\n",
        "        # Attention\n",
        "        for layer in self.attentions:\n",
        "            x = layer(x, x_memory, x_memory)\n",
        "\n",
        "        # RNN\n",
        "        x, hidden = self.gru(x, hidden)\n",
        "        return x, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(self.rnn_hidden_size, 1, self.rnn_dim).to(cfg.DEVICE)\n",
        "\n",
        "\n",
        "class Decoder(torch.nn.Module):\n",
        "    def __init__(self, output_dim, hidden_dim=64, rnn_dim=64, attention_dim=64, dropout_p=0.1,\n",
        "        attention_time=1, max_length=100, use_source_target_attention=False, use_self_attention=False,\n",
        "        multiHead_attention_num=2, use_FFN=False, FFN_dim=2048, use_PE=False, use_bd=False):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "\n",
        "        # Embedding\n",
        "        self.input_embedding = torch.nn.Embedding(output_dim, hidden_dim)\n",
        "        self.input_embedding_dropout = torch.nn.Dropout(dropout_p)\n",
        "\n",
        "        # Positional Encoding\n",
        "        if use_PE:\n",
        "            self.pe = PE()\n",
        "\n",
        "        # Attention\n",
        "        self.attentions = []\n",
        "        if attention_time > 0:\n",
        "            for i in range(attention_time):\n",
        "                # Self Attention\n",
        "                if use_self_attention:\n",
        "                    self.attentions.append(\n",
        "                        Attention(hidden_dim=hidden_dim, memory_dim=hidden_dim, attention_dim=attention_dim, output_dim=hidden_dim,\n",
        "                        dropout_p=dropout_p, max_length=max_length, self_attention=use_self_attention, head_num=multiHead_attention_num))\n",
        "                \n",
        "                # Source Target Attention\n",
        "                if use_source_target_attention:\n",
        "                    self.attentions.append(\n",
        "                        Attention(hidden_dim=hidden_dim, memory_dim=rnn_dim * (use_bd + 1), attention_dim=attention_dim, output_dim=hidden_dim,\n",
        "                        dropout_p=dropout_p, max_length=max_length, head_num=multiHead_attention_num))\n",
        "\n",
        "                # Feed Forward Network\n",
        "                if use_FFN:\n",
        "                    self.attentions.append(FFN(dim=FFN_dim, d_model=hidden_dim, dropout_p=dropout_p))\n",
        "\n",
        "        self.attentions = torch.nn.ModuleList(self.attentions)\n",
        "\n",
        "        # output GRU\n",
        "        self.gru = torch.nn.GRU(hidden_dim, rnn_dim, bidirectional=use_bd)\n",
        "        self.out = torch.nn.Sequential(\n",
        "            torch.nn.Linear(rnn_dim * (use_bd + 1), output_dim),\n",
        "            torch.nn.Softmax(dim=-1)\n",
        "        )\n",
        "    \n",
        "\n",
        "    def forward(self, x, hidden, x_memory_encoder, x_self_memory):\n",
        "        # Embedding\n",
        "        x = self.input_embedding(x)\n",
        "        x = self.input_embedding_dropout(x)\n",
        "\n",
        "        # Memory Embedding\n",
        "        x_self_memory = self.input_embedding(x_self_memory)#.permute(1, 0, 2)\n",
        "\n",
        "        # Positional Encoding\n",
        "        if hasattr(self, \"pe\"):\n",
        "            x = self.pe(x)\n",
        "            x_self_memory = self.pe(x_self_memory)\n",
        "\n",
        "        # Attention\n",
        "        for layer in self.attentions:\n",
        "            x = layer(x, x_memory_encoder, x_self_memory)\n",
        "\n",
        "        # output GRU\n",
        "        x, hidden = self.gru(x, hidden)\n",
        "        x = self.out(x[0])\n",
        "        return x, hidden\n",
        "\n",
        "\n",
        "\n",
        "class Attention(torch.nn.Module):\n",
        "    def __init__(self, hidden_dim, memory_dim, attention_dim, output_dim, dropout_p=0.1, max_length=100, head_num=1, self_attention=False):\n",
        "        super(Attention, self).__init__()\n",
        "        self.max_length = max_length\n",
        "        self.self_attention = self_attention\n",
        "\n",
        "        # Attention Query\n",
        "        self.Q = torch.nn.Sequential(\n",
        "            Reshape([1, -1]),\n",
        "            torch.nn.Linear(hidden_dim, attention_dim),\n",
        "            torch.nn.Dropout(dropout_p),\n",
        "            Reshape([1, 1, -1]),\n",
        "            Reshape([1, attention_dim // head_num, head_num]), # Multi head attention\n",
        "            Permute(2, 0, 1),\n",
        "        )\n",
        "        \n",
        "        # Attention Key\n",
        "        self.K = torch.nn.Sequential(\n",
        "            torch.nn.Linear(memory_dim, attention_dim),\n",
        "            torch.nn.Dropout(dropout_p),\n",
        "            Reshape([1, -1, attention_dim]),\n",
        "            Reshape([-1, attention_dim // head_num, head_num]), # Multi head attention\n",
        "            Permute(2, 1, 0)\n",
        "        )\n",
        "        \n",
        "        # Attetion Value\n",
        "        self.V = torch.nn.Sequential(\n",
        "            torch.nn.Linear(memory_dim, attention_dim),\n",
        "            torch.nn.Dropout(dropout_p),\n",
        "            Reshape([1, -1, attention_dim]),\n",
        "            Reshape([-1, attention_dim // head_num, head_num]), # Multi head attention\n",
        "            Permute(2, 0, 1),\n",
        "        )\n",
        "\n",
        "        self.out = torch.nn.Sequential(\n",
        "            torch.nn.Linear(attention_dim, output_dim),\n",
        "            torch.nn.Dropout(dropout_p)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x, memory, memory2):\n",
        "        # get Query\n",
        "        Q = self.Q(x)\n",
        "        Q *= Q.size()[-1] ** -0.5 # scaled dot product\n",
        "\n",
        "        if self.self_attention:\n",
        "            memory = memory2\n",
        "\n",
        "        # memory transforme [mb(=1), length, dim] -> [length, dim]\n",
        "        if len(memory.size()) > 2:\n",
        "            memory = memory[0]\n",
        "        \n",
        "        # get Key\n",
        "        K = self.K(memory)\n",
        "\n",
        "        QK = torch.bmm(Q, K) # get Query and Key (= attention logits)\n",
        "\n",
        "        # masking attention weight\n",
        "        any_zero = memory.sum(dim=1)\n",
        "        pad_mask = torch.ones([1, 1, self.max_length]).to(cfg.DEVICE)\n",
        "        pad_mask[:, :, torch.nonzero(any_zero)] = 0\n",
        "\n",
        "        pad_mask = pad_mask[:, :, :QK.size()[-1]] # crop \n",
        "        QK += pad_mask * 1e-10\n",
        "        attention_weights = F.softmax(QK, dim=-1) # get attention weight\n",
        "        \n",
        "        # get Value\n",
        "        V = self.V(memory)\n",
        "        \n",
        "        # Attetion x Value\n",
        "        x = torch.bmm(attention_weights, V)\n",
        "\n",
        "        # Multi head -> one head\n",
        "        x = x.permute(1, 2, 0).reshape(1, 1, -1)\n",
        "        return self.out(x)\n",
        "\n",
        "\n",
        "class FFN(torch.nn.Module):\n",
        "    def __init__(self, dim, d_model, dropout_p=0.1):\n",
        "        super(FFN, self).__init__()\n",
        "\n",
        "        self.module = torch.nn.Sequential(\n",
        "            torch.nn.Linear(d_model, dim),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Dropout(dropout_p),\n",
        "            torch.nn.Linear(dim, d_model)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, memory_encoder, decoder):\n",
        "        return self.module(x)\n",
        "\n",
        "class PE(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(PE, self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        mb, pos, dim = x.size()\n",
        "        pe = np.zeros_like(x.detach().cpu().numpy())\n",
        "        pos_i, dim_i = np.meshgrid(np.arange(dim), np.arange(pos))\n",
        "        pe[..., 0::2] = np.sin(pos_i[..., 0::2] / (10000 ** (2 * dim_i[..., 0::2] / dim)))\n",
        "        pe[..., 1::2] = np.cos(pos_i[..., 1::2] / (10000 ** (2 * dim_i[..., 1::2] / dim)))\n",
        "        pe = torch.tensor(pe).to(cfg.DEVICE)\n",
        "        return x + pe\n",
        "\n",
        "\n",
        "class HRED(torch.nn.Module):\n",
        "    def __init__(self, decoder_dim, hidden_dim, num_layers=1, use_bd=False):\n",
        "        super(HRED, self).__init__()\n",
        "        self.HRED_hidden_dim = hidden_dim\n",
        "        self.tensor_dim = use_bd + 1\n",
        "\n",
        "        # output GRU\n",
        "        self.gru = torch.nn.GRU(decoder_dim * (use_bd + 1), self.HRED_hidden_dim, num_layers=num_layers, bidirectional=use_bd)\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        x, hidden = self.gru(x, hidden)\n",
        "        return x, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros([self.tensor_dim, 1, self.HRED_hidden_dim], device=cfg.DEVICE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWdUenQ8khEc",
        "colab_type": "text"
      },
      "source": [
        "# Utility"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rw9HD3tjkhEc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MInibatch_Generator():\n",
        "    def __init__(self, data_size, batch_size, shuffle=True):\n",
        "        self.data_size = data_size\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.mbi = 0 # index for iteration\n",
        "        self.inds = np.arange(data_size)\n",
        "        np.random.shuffle(self.inds)\n",
        "\n",
        "    def __call__(self):\n",
        "        if self.mbi + self.batch_size > self.data_size:\n",
        "            inds = self.inds[self.mbi:]\n",
        "            if self.shuffle:\n",
        "                np.random.shuffle(self.inds)\n",
        "            inds = np.hstack((inds, self.inds[ : (self.batch_size - (self.data_size - self.mbi))]))\n",
        "            mbi = self.batch_size - (self.data_size - self.mbi)\n",
        "        else:\n",
        "            inds = self.inds[self.mbi : self.mbi + self.batch_size]\n",
        "            self.mbi += self.batch_size\n",
        "        return inds\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvsBhxJzkhEe",
        "colab_type": "text"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "u93U8jihkhEe",
        "colab_type": "code",
        "outputId": "9b64cd3e-f2f2-4a3a-a322-15f7a55dbbf5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# train\n",
        "def train():\n",
        "    # model\n",
        "    E = Encoder(\n",
        "        input_dim = cfg.CORPUS1_NUM, \n",
        "        hidden_dim = cfg.SEQ2SEQ_E_DIM,\n",
        "        attention_dim = cfg.SEQ2SEQ_E_ATTENTION_DIM,\n",
        "        rnn_dim = cfg.SEQ2SEQ_RNN_DIM,\n",
        "        rnn_hidden_size = cfg.SEQ2SEQ_USE_RNN_BD + 1,\n",
        "        use_bd = cfg.SEQ2SEQ_USE_RNN_BD,\n",
        "        dropout_p = cfg.SEQ2SEQ_E_DROPOUT,\n",
        "        attention_time = cfg.SEQ2SEQ_E_ATTENTION_TIME,\n",
        "        use_source_target_attention = cfg.SEQ2SEQ_E_USE_SOURCE_TARGET_ATTENTION,\n",
        "        use_self_attention = cfg.SEQ2SEQ_E_USE_SELF_ATTENTION,\n",
        "        multiHead_attention_num = cfg.SEQ2SEQ_E_MULTIHEAD_ATTENTION_N,\n",
        "        use_FFN = cfg.SEQ2SEQ_E_USE_FFN,\n",
        "        FFN_dim = cfg.SEQ2SEQ_E_FFN_DIM,\n",
        "        use_PE = cfg.SEQ2SEQ_E_USE_PE,\n",
        "        max_length = cfg.SEQ2SEQ_MAX_LENGTH\n",
        "        ).to(cfg.DEVICE) \n",
        "\n",
        "    D = Decoder(\n",
        "        output_dim = cfg.CORPUS2_NUM, \n",
        "        hidden_dim = cfg.SEQ2SEQ_E_DIM,\n",
        "        rnn_dim = cfg.SEQ2SEQ_RNN_DIM,\n",
        "        use_bd = cfg.SEQ2SEQ_USE_RNN_BD,\n",
        "        attention_dim = cfg.SEQ2SEQ_E_ATTENTION_DIM,\n",
        "        dropout_p = cfg.SEQ2SEQ_E_DROPOUT,\n",
        "        attention_time = cfg.SEQ2SEQ_E_ATTENTION_TIME,\n",
        "        use_source_target_attention = cfg.SEQ2SEQ_E_USE_SOURCE_TARGET_ATTENTION,\n",
        "        use_self_attention = cfg.SEQ2SEQ_E_USE_SELF_ATTENTION,\n",
        "        multiHead_attention_num = cfg.SEQ2SEQ_E_MULTIHEAD_ATTENTION_N,\n",
        "        use_FFN = cfg.SEQ2SEQ_E_USE_FFN,\n",
        "        FFN_dim = cfg.SEQ2SEQ_E_FFN_DIM,\n",
        "        use_PE = cfg.SEQ2SEQ_E_USE_PE,\n",
        "        max_length = cfg.SEQ2SEQ_MAX_LENGTH\n",
        "        ).to(cfg.DEVICE)\n",
        "\n",
        "    H = HRED(\n",
        "        decoder_dim=cfg.SEQ2SEQ_RNN_DIM,\n",
        "        hidden_dim=cfg.HRED_HIDDEN_DIM,\n",
        "        use_bd=cfg.SEQ2SEQ_USE_RNN_BD\n",
        "    ).to(cfg.DEVICE)\n",
        "\n",
        "    #summary(E, (cfg.INPUT_Z_DIM, 1, 1), device=cfg.DEVICE_TYPE)\n",
        "    #summary(D, (cfg.OUTPUT_CHANNEL, cfg.OUTPUT_HEIGHT, cfg.OUTPUT_WIDTH), device=cfg.DEVICE_TYPE)\n",
        "    \n",
        "    opt_E = cfg.TRAIN.OPTIMIZER_E(E.parameters(), **cfg.TRAIN.LEARNING_PARAMS_E)\n",
        "    opt_D = cfg.TRAIN.OPTIMIZER_D(D.parameters(), **cfg.TRAIN.LEARNING_PARAMS_D)\n",
        "    opt_H = cfg.TRAIN.OPTIMIZER_H(H.parameters(), **cfg.TRAIN.LEARNING_PARAMS_H)\n",
        "\n",
        "    list_iter = []\n",
        "    list_loss = []\n",
        "    list_accuracy = []\n",
        "\n",
        "    #dataset = MyDataset(data_dict['data1'], data_dict['data2'])\n",
        "    #dataloader = torch.utils.data.DataLoader(dataset, batch_size=cfg.TRAIN.MINIBATCH, shuffle=True)\n",
        "\n",
        "    mb_gen = MInibatch_Generator(len(data_Xs), cfg.TRAIN.MINIBATCH)\n",
        "\n",
        "    print('training start')\n",
        "    progres_bar = ''\n",
        "\n",
        "    Xs_train = data_Xs\n",
        "    #ts_train = data_dict['data2']\n",
        "\n",
        "    for i in range(cfg.TRAIN.ITERATION):\n",
        "        idxs = mb_gen()\n",
        "        loss = 0.\n",
        "        accuracy = 0.\n",
        "        total_len = 0.\n",
        "        _Xs = [Xs_train[idx] for idx in idxs]\n",
        "        #_ts = [ts_train[idx] for idx in idxs]\n",
        "\n",
        "        # each iteration in minibatch\n",
        "        opt_E.zero_grad()\n",
        "        opt_D.zero_grad()\n",
        "        opt_H.zero_grad()\n",
        "\n",
        "        for mbi in range(cfg.TRAIN.MINIBATCH):\n",
        "            Xs_mb = _Xs[mbi]\n",
        "\n",
        "            # encode process\n",
        "            E_hidden = E.initHidden() # initialize encoder hidden\n",
        "            H_hidden = H.initHidden() # initialize hred hidden\n",
        "\n",
        "            for sess_i in range(HRED_SESSION - 1):\n",
        "                E_outputs = torch.zeros(cfg.SEQ2SEQ_MAX_LENGTH, cfg.SEQ2SEQ_RNN_DIM * (cfg.SEQ2SEQ_USE_RNN_BD + 1)).to(cfg.DEVICE)\n",
        "\n",
        "                Xs = torch.tensor(Xs_mb[sess_i]).reshape(-1, 1).to(cfg.DEVICE)\n",
        "                ts = torch.tensor(Xs_mb[sess_i + 1]).reshape(-1, 1).to(cfg.DEVICE)\n",
        "\n",
        "\n",
        "                xs_length = Xs.size()[0]\n",
        "                ts_length = ts.size()[0]\n",
        "\n",
        "                total_len += ts_length\n",
        "\n",
        "                for ei in range(xs_length):\n",
        "                    E_output, E_hidden = E(Xs[ei], E_hidden, Xs)\n",
        "                    E_outputs[ei] = E_output[0, 0]\n",
        "\n",
        "                # hred\n",
        "                hred_output, H_hidden = H(E_output, H_hidden)\n",
        "\n",
        "                # decode process\n",
        "                D_xs = ts[0].reshape(1, -1) # define decoder input\n",
        "                D_hidden = H_hidden # define decoder hidden\n",
        "                D_self_memory = D_xs\n",
        "                D_outputs = []\n",
        "\n",
        "                # define whethere if use teacher label for decoder input\n",
        "                use_teacher = True if np.random.random() < cfg.SEQ2SEQ_TRAIN_FORCE_PROB else False\n",
        "\n",
        "                for di in range(1, ts_length):\n",
        "                    # decode\n",
        "                    D_ys, D_hidden = D(D_xs, D_hidden, E_outputs, D_self_memory)\n",
        "\n",
        "                    # add loss\n",
        "                    loss += cfg.TRAIN.LOSS_FUNCTION(torch.log(D_ys), ts[di])\n",
        "\n",
        "                    # count accuracy\n",
        "                    if D_ys.argmax() == ts[di]:\n",
        "                        accuracy += 1.\n",
        "\n",
        "                    D_ys = torch.where(torch.isnan(D_ys), torch.zeros_like(D_ys), D_ys)\n",
        "                    D_ys = torch.max(D_ys, torch.zeros_like(D_ys) + 1e-5)\n",
        "                    D_ys /= torch.sum(D_ys)\n",
        "                    \n",
        "                    if cfg.SEQ2SEQ_NEXT_WORD_SELECTION == \"argmax\":\n",
        "                        topv, topi = D_ys.data.topk(1)\n",
        "\n",
        "                    elif cfg.SEQ2SEQ_NEXT_WORD_SELECTION == \"prob\":\n",
        "                        topi = torch.multinomial(torch.max(D_ys, torch.zeros_like(D_ys)), 1)\n",
        "                    \n",
        "                    # define next decoder input\n",
        "                    if use_teacher:\n",
        "                        D_xs = ts[di] # teacher forcing\n",
        "                    else:\n",
        "                        D_xs = topi#.squeeze().detach()\n",
        "\n",
        "                    D_xs = D_xs.reshape(1, -1)\n",
        "                    D_self_memory = torch.cat([D_self_memory, D_xs])\n",
        "\n",
        "                    D_outputs.append(topi.detach().cpu().numpy()[0])\n",
        "                        \n",
        "                    # if EOS, finish training\n",
        "                    #if D_xs.item() == data_dict['corpus2'].index('<EOS>'):\n",
        "                    #    break\n",
        "\n",
        "\n",
        "        loss.backward()\n",
        "        opt_D.step()\n",
        "\n",
        "        _loss = loss.item() / cfg.TRAIN.MINIBATCH\n",
        "        _accuracy = accuracy / total_len\n",
        "\n",
        "        progres_bar += '|'\n",
        "        print('\\r' + 'Loss:{:.4f}, Accu:{:.4f} '.format(_loss, _accuracy) + progres_bar, end='')\n",
        "\n",
        "        if (i + 1) % 10 == 0:\n",
        "            progres_bar += str(i + 1)\n",
        "            print('\\r' + 'Loss:{:.4f}, Accu:{:.4f} '.format(_loss, _accuracy) + progres_bar, end='')\n",
        "\n",
        "            # save process result\n",
        "            if cfg.TRAIN.LEARNING_PROCESS_RESULT_SAVE:\n",
        "                list_iter.append(i + 1)\n",
        "                list_loss.append(_loss)\n",
        "                list_accuracy.append(_accuracy)\n",
        "\n",
        "        # display training state\n",
        "        if (i + 1) % cfg.TRAIN.DISPAY_ITERATION_INTERVAL == 0:\n",
        "            print('\\r' + ' ' * (len(progres_bar) + 50), end='')\n",
        "            print('\\rIter:{}, Loss:{:.4f}, Accu:{:.4f}'.format(i + 1, _loss, _accuracy))\n",
        "            progres_bar = ''\n",
        "\n",
        "        # save parameters\n",
        "        if (cfg.TRAIN.MODEL_SAVE_INTERVAL != False) and ((i + 1) % cfg.TRAIN.MODEL_SAVE_INTERVAL == 0):\n",
        "            E_save_path = cfg.TRAIN.MODEL_E_SAVE_PATH.format('iter{}'.format(i + 1))\n",
        "            D_save_path = cfg.TRAIN.MODEL_D_SAVE_PATH.format('iter{}'.format(i + 1))\n",
        "            torch.save(E.state_dict(), E_save_path)\n",
        "            torch.save(D.state_dict(), D_save_path)\n",
        "            print('save E >> {}, D >> {}'.format(E_save_path, D_save_path))\n",
        "\n",
        "        # save process result\n",
        "        if cfg.TRAIN.LEARNING_PROCESS_RESULT_SAVE and ((i + 1) % cfg.TRAIN.LEARNING_PROCESS_RESULT_INTERVAL == 0):\n",
        "            print('iter :', i + 1)\n",
        "            print(' - [input]', ' '.join([corpus[x] for x in Xs_mb[HRED_SESSION - 2]]))\n",
        "            print(' - [output]', ' '.join([corpus[int(x)] for x in D_outputs])) #if x not in [0, 1, 2]]))\n",
        "            print(' - [gt]', ' '.join([corpus[x] for x in Xs_mb[HRED_SESSION - 1]]))\n",
        "\n",
        "    E_save_path = cfg.TRAIN.MODEL_E_SAVE_PATH.format('final')\n",
        "    D_save_path = cfg.TRAIN.MODEL_D_SAVE_PATH.format('final')\n",
        "    torch.save(E.state_dict(), E_save_path)\n",
        "    torch.save(D.state_dict(), D_save_path)\n",
        "    print('final paramters were saved to E >> {}, D >> {}'.format(E_save_path, D_save_path))\n",
        "\n",
        "    if cfg.TRAIN.LEARNING_PROCESS_RESULT_SAVE:\n",
        "        f = open(cfg.TRAIN.LEARNING_PROCESS_RESULT_LOSS_PATH, 'w')\n",
        "        df = pd.DataFrame({'iteration' : list_iter, 'loss' : list_loss, 'accuracy' : list_accuracy})\n",
        "        df.to_csv(cfg.TRAIN.LEARNING_PROCESS_RESULT_LOSS_PATH, index=False)\n",
        "        print('loss was saved to >> {}'.format(cfg.TRAIN.LEARNING_PROCESS_RESULT_LOSS_PATH))\n",
        "\n",
        "train()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training start\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
            "\tnonzero(Tensor input, *, Tensor out)\n",
            "Consider using one of the following signatures instead:\n",
            "\tnonzero(Tensor input, *, bool as_tuple)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter:50, Loss:548.3168, Accu:0.0120\n",
            "Iter:100, Loss:1457.7521, Accu:0.0000\n",
            "Iter:150, Loss:556.4438, Accu:0.0471\n",
            "Iter:200, Loss:360.9281, Accu:0.0000\n",
            "save E >> models/Seq2seq-Attention_E_iter200.pt, D >> models/Seq2seq-Attention_D_iter200.pt\n",
            "iter : 200\n",
            " - [input] <SOS> 葬儀 １ 回 無料 プラス 坊主 が 100 人 来る ん です 。 <EOS>\n",
            " - [output] 無線 に そう は てる に に これ に に だ か ください に です に ください が パトカー\n",
            " - [gt] <SOS> 気持ち わりー よ 、 お前 。 なん だ 坊主 が 100 人 って 、 気持ち わりー な 。 <EOS>\n",
            "Iter:250, Loss:550.8776, Accu:0.0000\n",
            "Iter:300, Loss:294.2032, Accu:0.0222\n",
            "Iter:350, Loss:544.7263, Accu:0.0312\n",
            "Iter:400, Loss:664.7424, Accu:0.0506\n",
            "save E >> models/Seq2seq-Attention_E_iter400.pt, D >> models/Seq2seq-Attention_D_iter400.pt\n",
            "iter : 400\n",
            " - [input] <SOS> 高橋 が ちぢれ て こじれ た 話 を 始める 先生 は みじめ だ 。 <EOS>\n",
            " - [output] た た た なかっ に は た 高校 た 途中 た <EOS> 。 は た た だろ た は は 出 は\n",
            " - [gt] <SOS> 何 言っ てる か 、 全然 わから ん わ 。 何 言っ て ん だ よ 、 さっき から よ 。 <EOS>\n",
            "Iter:450, Loss:728.8397, Accu:0.0000\n",
            "Iter:500, Loss:256.3638, Accu:0.0000\n",
            "Iter:550, Loss:160.8903, Accu:0.0000\n",
            "Iter:600, Loss:727.6642, Accu:0.0482\n",
            "save E >> models/Seq2seq-Attention_E_iter600.pt, D >> models/Seq2seq-Attention_D_iter600.pt\n",
            "iter : 600\n",
            " - [input] <SOS> どんな コース だ よ 、 お前 。 普通 、 松 ・ 竹 ・ 梅 の 松竹 梅 だろ 、 お前 。 なん だ 、 松 ・ たか ・ 子 って 。 かわいい な 、 おい 。 ええ ？ で 、 １番 オーソドックス な の は どこ な の ？ そん 中 で … <EOS>\n",
            " - [output] の 死ん ある いじめ\n",
            " - [gt] <SOS> １番 オートバックス ？ <EOS>\n",
            "Iter:650, Loss:716.4022, Accu:0.0260\n",
            "Iter:700, Loss:369.7098, Accu:0.0000\n",
            "Iter:750, Loss:253.7162, Accu:0.0222\n",
            "Iter:800, Loss:346.5251, Accu:0.0408\n",
            "save E >> models/Seq2seq-Attention_E_iter800.pt, D >> models/Seq2seq-Attention_D_iter800.pt\n",
            "iter : 800\n",
            " - [input] <SOS> 酒 の 匂い し たら アウト 。 <EOS>\n",
            " - [output] です し です から か です 「 「 年 た から\n",
            " - [gt] <SOS> どれ ぐらい 飲み まし た ？ ビール 1 杯 。 <EOS>\n",
            "Iter:850, Loss:489.1392, Accu:0.0625\n",
            "Iter:900, Loss:433.6336, Accu:0.0645\n",
            "Iter:950, Loss:485.7028, Accu:0.0952\n",
            "Iter:1000, Loss:294.7309, Accu:0.0233\n",
            "save E >> models/Seq2seq-Attention_E_iter1000.pt, D >> models/Seq2seq-Attention_D_iter1000.pt\n",
            "iter : 1000\n",
            " - [input] <SOS> 何 それ 。 <EOS>\n",
            " - [output] だ ！ ！ よー ござい ん ？ な か お前 た 何 ！ ん 名前 お か ！ もらっ な だ\n",
            " - [gt] <SOS> 今 、 結構 亡くなる 前 に こんな 葬儀 に し たい って 決める 方 が 多い ん です よ 。 <EOS>\n",
            "Iter:1050, Loss:490.1238, Accu:0.0172\n",
            "Iter:1100, Loss:704.7603, Accu:0.0000\n",
            "Iter:1150, Loss:629.0306, Accu:0.0000\n",
            "Iter:1200, Loss:679.3361, Accu:0.0000\n",
            "save E >> models/Seq2seq-Attention_E_iter1200.pt, D >> models/Seq2seq-Attention_D_iter1200.pt\n",
            "iter : 1200\n",
            " - [input] <SOS> 私 酒 なんか 飲ん で ませ ん けど 。 <EOS>\n",
            " - [output] って って 」 が か って が って って か なっ って が お って って が が って って くれ が\n",
            " - [gt] <SOS> 酒 どころ の 話 じゃ ねえ 。 薬 打っ てる 最中 じゃ ねえ か 。 バカ じゃ ない の こいつ 。 <EOS>\n",
            "Iter:1250, Loss:276.1726, Accu:0.1053\n",
            "Iter:1300, Loss:749.3987, Accu:0.0000\n",
            "Iter:1350, Loss:383.8825, Accu:0.0000\n",
            "Iter:1400, Loss:319.2152, Accu:0.0500\n",
            "save E >> models/Seq2seq-Attention_E_iter1400.pt, D >> models/Seq2seq-Attention_D_iter1400.pt\n",
            "iter : 1400\n",
            " - [input] <SOS> うるせぇ な 。 <EOS>\n",
            " - [output] 中 も これ なら ふざけ 、 よ 高飛び しか 。 お前 宴 じゃ お ん じゃあ\n",
            " - [gt] <SOS> 「 うるせぇ な 」 じゃ ない 。 盛り上がっ て くれ てる わけ です よ 。 <EOS>\n",
            "Iter:1450, Loss:503.6063, Accu:0.0370\n",
            "Iter:1500, Loss:167.7395, Accu:0.0000\n",
            "Iter:1550, Loss:587.8875, Accu:0.0448\n",
            "Iter:1600, Loss:488.3791, Accu:0.0149\n",
            "save E >> models/Seq2seq-Attention_E_iter1600.pt, D >> models/Seq2seq-Attention_D_iter1600.pt\n",
            "iter : 1600\n",
            " - [input] <SOS> 悪い と 思っ てる わ 。 <EOS>\n",
            " - [output] 」 いじっ の の の <EOS> を に <EOS> から じゃあ … 」 聞い <EOS> 何 れ … 」 気 の を 「 から 感じ を 伊達 ます 。\n",
            " - [gt] <SOS> よし 分かっ た 。 お前 が もし 高橋 を 今度 けじめ てん の を 見 たら 、 先生 お前 を 真っ 二 つ に する から な 。 <EOS>\n",
            "Iter:1650, Loss:383.4434, Accu:0.0213\n",
            "Iter:1700, Loss:332.8144, Accu:0.0909\n",
            "Iter:1750, Loss:174.9034, Accu:0.1176\n",
            "Iter:1800, Loss:413.5183, Accu:0.0429\n",
            "save E >> models/Seq2seq-Attention_E_iter1800.pt, D >> models/Seq2seq-Attention_D_iter1800.pt\n",
            "iter : 1800\n",
            " - [input] <SOS> ナン の 話し て た ん だ ！ ナン の 話し て た ん だ ！ <EOS>\n",
            " - [output] だけ なぁ もう か ただ ねー\n",
            " - [gt] <SOS> なーん と なく です ！ <EOS>\n",
            "Iter:1850, Loss:403.4424, Accu:0.0000\n",
            "Iter:1900, Loss:607.8593, Accu:0.0556\n",
            "Iter:1950, Loss:646.0187, Accu:0.0485\n",
            "Iter:2000, Loss:501.1639, Accu:0.0000\n",
            "save E >> models/Seq2seq-Attention_E_iter2000.pt, D >> models/Seq2seq-Attention_D_iter2000.pt\n",
            "iter : 2000\n",
            " - [input] <SOS> まぁ 、 国内 に しよう か な って 思っ て ん だ よ ね 。 <EOS>\n",
            " - [output] 入っ 食べ 入っ 入っ 入っ 」 誰\n",
            " - [gt] <SOS> あ ！ 国内 です か ！ <EOS>\n",
            "Iter:2050, Loss:551.2678, Accu:0.0000\n",
            "Iter:2100, Loss:122.6487, Accu:0.1429\n",
            "Iter:2150, Loss:389.3260, Accu:0.0000\n",
            "Iter:2200, Loss:523.1873, Accu:0.0152\n",
            "save E >> models/Seq2seq-Attention_E_iter2200.pt, D >> models/Seq2seq-Attention_D_iter2200.pt\n",
            "iter : 2200\n",
            " - [input] <SOS> どっち も お 尻 じゃ ない よ 。 そんな 気持ち 悪い 動物 散歩 さ せる か 。 家 に 置い とく わ それ だっ たら 。 <EOS>\n",
            " - [output] は 回 豪華 。 に は て お前 だ だ ん １ しか １ を しれ\n",
            " - [gt] <SOS> あっ そう っす か 。 あっ 名前 は 何 て いう ん です か ？ <EOS>\n",
            "Iter:2250, Loss:388.3276, Accu:0.0370\n",
            "Iter:2300, Loss:676.4722, Accu:0.0779\n",
            "Iter:2350, Loss:320.6115, Accu:0.0000\n",
            "Iter:2400, Loss:523.9460, Accu:0.0000\n",
            "save E >> models/Seq2seq-Attention_E_iter2400.pt, D >> models/Seq2seq-Attention_D_iter2400.pt\n",
            "iter : 2400\n",
            " - [input] <SOS> 「 これ は ニーチェ の 言葉 です 」 。 <EOS>\n",
            " - [output] も も も ちょっと です も なる\n",
            " - [gt] <SOS> 素晴らしい さすが ニーチェ だ ね 。 <EOS>\n",
            "Iter:2450, Loss:523.1035, Accu:0.0385\n",
            "Iter:2500, Loss:674.5659, Accu:0.0143\n",
            "Iter:2550, Loss:1290.6069, Accu:0.0076\n",
            "Iter:2600, Loss:652.9572, Accu:0.0645\n",
            "save E >> models/Seq2seq-Attention_E_iter2600.pt, D >> models/Seq2seq-Attention_D_iter2600.pt\n",
            "iter : 2600\n",
            " - [input] <SOS> 「 この あと ささやか ながら 二 次 会 も ござい ます の で … 」 <EOS>\n",
            " - [output] <EOS> 。 が まし 。 くらい 。 もん あ そう ふざけん 。 らしい だろ <EOS> <EOS> 犬 。 これ あと 、\n",
            " - [gt] <SOS> なん の 二 次 会 だ よ お前 。 聞い た 事 ねえ 葬式 の 二 次 会 お前 。 <EOS>\n",
            "Iter:2650, Loss:213.6918, Accu:0.0303\n",
            "Iter:2700, Loss:574.1339, Accu:0.0328\n",
            "Iter:2750, Loss:631.1339, Accu:0.0506\n",
            "Iter:2800, Loss:181.6643, Accu:0.0000\n",
            "save E >> models/Seq2seq-Attention_E_iter2800.pt, D >> models/Seq2seq-Attention_D_iter2800.pt\n",
            "iter : 2800\n",
            " - [input] <SOS> はい 。 <EOS>\n",
            " - [output] から 内閣 ありがとう うん の <EOS>\n",
            " - [gt] <SOS> はい 、 ５千 円 。 <EOS>\n",
            "Iter:2850, Loss:306.9018, Accu:0.0217\n",
            "Iter:2900, Loss:243.9804, Accu:0.0465\n",
            "Iter:2950, Loss:643.2088, Accu:0.0000\n",
            "Iter:3000, Loss:446.4203, Accu:0.0800\n",
            "save E >> models/Seq2seq-Attention_E_iter3000.pt, D >> models/Seq2seq-Attention_D_iter3000.pt\n",
            "iter : 3000\n",
            " - [input] <SOS> それ が 腹 の 減っ てる 人間 の 体形 か 。 <EOS>\n",
            " - [output] て <EOS> ぞ た だ <EOS> を よ <EOS> か <EOS> か か て <EOS> お ドロップ <EOS> 鬼 だ <EOS> か <EOS>\n",
            " - [gt] <SOS> や かま しー わ 。 ほっ とけよ そんな の 、 うっせ ー な 。 なん な ん だ よ 、 お前 。 <EOS>\n",
            "Iter:3050, Loss:470.3327, Accu:0.0526\n",
            "Iter:3100, Loss:577.4103, Accu:0.0000\n",
            "Iter:3150, Loss:510.6225, Accu:0.0000\n",
            "Iter:3200, Loss:447.1504, Accu:0.0182\n",
            "save E >> models/Seq2seq-Attention_E_iter3200.pt, D >> models/Seq2seq-Attention_D_iter3200.pt\n",
            "iter : 3200\n",
            " - [input] <SOS> あっ じゃあ あの ほら 缶詰 に 入っ てる … 。 ドッグフード 。 <EOS>\n",
            " - [output] て て か じゃ なん か か なん か か て <EOS> か ます か わけ 始め わけ わけ と て か\n",
            " - [gt] <SOS> ぶっ壊れ てん の か お前 。 ドッグフード は いい ん だ よ ！ ドッグフード しか 食わ ねえ ん だ から 。 <EOS>\n",
            "Iter:3250, Loss:503.7190, Accu:0.0175\n",
            "Iter:3300, Loss:499.4411, Accu:0.0000\n",
            "Iter:3350, Loss:551.4736, Accu:0.0000\n",
            "Iter:3400, Loss:707.2341, Accu:0.0380\n",
            "save E >> models/Seq2seq-Attention_E_iter3400.pt, D >> models/Seq2seq-Attention_D_iter3400.pt\n",
            "iter : 3400\n",
            " - [input] <SOS> 「 体育 の 時間 体操着 を 忘れ た 僕 に そっと エビフライ を くれ た こと 」 。 <EOS>\n",
            " - [output] 。 。 あの 、 なんか の あの 、 し 、 。 ん の なく さん 。 さん が です オーソドックス 、 ！ さん ！ さん て 。 なく 、\n",
            " - [gt] <SOS> 何 に 使っ た ん だ よ ！ 体育 の 時間 エビフライ 何 に 使う ん だ ! ? 衣 は い た の か ？ 衣 ！ <EOS>\n",
            "Iter:3450, Loss:259.8468, Accu:0.1277\n",
            "Iter:3500, Loss:634.9141, Accu:0.0426\n",
            "Iter:3550, Loss:539.6230, Accu:0.0000\n",
            "Iter:3600, Loss:362.9309, Accu:0.1020\n",
            "save E >> models/Seq2seq-Attention_E_iter3600.pt, D >> models/Seq2seq-Attention_D_iter3600.pt\n",
            "iter : 3600\n",
            " - [input] <SOS> わかん ない じゃ ない 。 色んな 所 行く じゃ ない です か 地方 と か も 。 <EOS>\n",
            " - [output] ！ な 会っ うん 。 な 男\n",
            " - [gt] <SOS> 色んな 所 行き ます よ 。 <EOS>\n",
            "Iter:3650, Loss:264.6789, Accu:0.0000\n",
            "Iter:3700, Loss:389.0528, Accu:0.0000\n",
            "Iter:3750, Loss:296.8817, Accu:0.0000\n",
            "Iter:3800, Loss:589.6357, Accu:0.0286\n",
            "save E >> models/Seq2seq-Attention_E_iter3800.pt, D >> models/Seq2seq-Attention_D_iter3800.pt\n",
            "iter : 3800\n",
            " - [input] <SOS> 昔むかし ある ところ に お じい さん と お じい さん に 似 た お ばあ さん が い まし た <EOS>\n",
            " - [output] なん を ん と 話 ん ん ん 満タン だ 。 た 話 を 両手 で 話 で ！ なん よ ねー ねー\n",
            " - [gt] <SOS> それ だっ たら お じい さん と お ばあ さん で いい と 思う ん だ けど 、 ややこしい 言い回し が な <EOS>\n",
            "Iter:3850, Loss:838.7009, Accu:0.0000\n",
            "Iter:3900, Loss:254.7910, Accu:0.0000\n",
            "Iter:3950, Loss:513.9828, Accu:0.0417\n",
            "Iter:4000, Loss:844.2305, Accu:0.0435\n",
            "save E >> models/Seq2seq-Attention_E_iter4000.pt, D >> models/Seq2seq-Attention_D_iter4000.pt\n",
            "iter : 4000\n",
            " - [input] <SOS> そして 反省 し てる と いえ ば ウソ に なる か も しれ ませ ん 。 <EOS>\n",
            " - [output] から ん て に てる ！ でしょ に から … に に に に に ね\n",
            " - [gt] <SOS> 反省 は しろ よ 。 謝罪 会見 でしょ ？ 反省 は しろ よ お前 。 <EOS>\n",
            "Iter:4050, Loss:490.3289, Accu:0.0159\n",
            "Iter:4100, Loss:501.4406, Accu:0.0000\n",
            "Iter:4150, Loss:471.3912, Accu:0.0000\n",
            "Iter:4200, Loss:276.3568, Accu:0.1026\n",
            "save E >> models/Seq2seq-Attention_E_iter4200.pt, D >> models/Seq2seq-Attention_D_iter4200.pt\n",
            "iter : 4200\n",
            " - [input] <SOS> サトル ！ <EOS>\n",
            " - [output] <EOS> <EOS> コース し <EOS> ね <EOS>\n",
            " - [gt] <SOS> サトル じゃ ねえ ！ みきお だ <EOS>\n",
            "Iter:4250, Loss:831.3401, Accu:0.0000\n",
            "Iter:4300, Loss:646.0994, Accu:0.0256\n",
            "Iter:4350, Loss:433.9625, Accu:0.0000\n",
            "Iter:4400, Loss:549.7490, Accu:0.0000\n",
            "save E >> models/Seq2seq-Attention_E_iter4400.pt, D >> models/Seq2seq-Attention_D_iter4400.pt\n",
            "iter : 4400\n",
            " - [input] <SOS> セクシャルハラスメント だ よ 。 それ お前 … 。 「 SexualViolet 」 桑名 さん の 歌 だ から ね 。 知っ てる の か な ？ <EOS>\n",
            " - [output] だ これ これ じゃあ て た <EOS> <EOS> て <EOS> <EOS> ください き て これ 。 ！ <EOS> <EOS> <EOS> これ ！ て 入れ 誰 だ ん\n",
            " - [gt] <SOS> 興奮 し て き た な 興奮 し て き た な と 何 度 も 私 に 声 を かけ て き まし た 。 <EOS>\n",
            "Iter:4450, Loss:392.6493, Accu:0.0256\n",
            "Iter:4500, Loss:222.7019, Accu:0.1042\n",
            "Iter:4550, Loss:369.5531, Accu:0.0233\n",
            "Iter:4600, Loss:571.5264, Accu:0.0000\n",
            "save E >> models/Seq2seq-Attention_E_iter4600.pt, D >> models/Seq2seq-Attention_D_iter4600.pt\n",
            "iter : 4600\n",
            " - [input] <SOS> 「 その とき だっ た ！ 」 パーパパパパパパーパパパパパ 。 <EOS>\n",
            " - [output] 聞い いじり って じい で ため は\n",
            " - [gt] <SOS> 暴走族 うるさい ね ホント に 。 <EOS>\n",
            "Iter:4650, Loss:782.4311, Accu:0.0128\n",
            "Iter:4700, Loss:416.1493, Accu:0.0625\n",
            "Iter:4750, Loss:1246.2556, Accu:0.0565\n",
            "Iter:4800, Loss:434.3738, Accu:0.0784\n",
            "save E >> models/Seq2seq-Attention_E_iter4800.pt, D >> models/Seq2seq-Attention_D_iter4800.pt\n",
            "iter : 4800\n",
            " - [input] <SOS> ご 協力 ありがとう ござい ます 。 <EOS>\n",
            " - [output] の 。 思い 「 の\n",
            " - [gt] <SOS> とんでも ない です 。 <EOS>\n",
            "Iter:4850, Loss:615.0170, Accu:0.0317\n",
            "Iter:4900, Loss:705.4634, Accu:0.0563\n",
            "Iter:4950, Loss:486.5188, Accu:0.0000\n",
            "Iter:5000, Loss:405.7062, Accu:0.1148\n",
            "save E >> models/Seq2seq-Attention_E_iter5000.pt, D >> models/Seq2seq-Attention_D_iter5000.pt\n",
            "iter : 5000\n",
            " - [input] <SOS> 黙秘権 か ？ <EOS>\n",
            " - [output] ？ … 。 わ 、 、 お前 <EOS> ね … <EOS> ？ 。 <EOS> 。 分かん 。 、 、 。 まし 。\n",
            " - [gt] <SOS> いや 、 いっぱい 喋っ てん じゃん 。 なぁ 。 何 、 黙秘権 の 意味 知ら ない ん じゃ ない の 。 <EOS>\n",
            "Iter:5050, Loss:569.0650, Accu:0.0667\n",
            "Iter:5100, Loss:580.9824, Accu:0.0690\n",
            "Iter:5150, Loss:690.7299, Accu:0.0147\n",
            "Iter:5200, Loss:583.0384, Accu:0.1000\n",
            "save E >> models/Seq2seq-Attention_E_iter5200.pt, D >> models/Seq2seq-Attention_D_iter5200.pt\n",
            "iter : 5200\n",
            " - [input] <SOS> ハハハハ 。 <EOS>\n",
            " - [output] よ 。 。 てん なっ 。 てん よ 。 。\n",
            " - [gt] <SOS> 汚い 手 で いじっ ちゃっ た ん です 。 <EOS>\n",
            "Iter:5250, Loss:354.5052, Accu:0.0000\n",
            "Iter:5300, Loss:658.2222, Accu:0.0822\n",
            "Iter:5350, Loss:512.4123, Accu:0.0000\n",
            "Iter:5400, Loss:727.8353, Accu:0.0984\n",
            "save E >> models/Seq2seq-Attention_E_iter5400.pt, D >> models/Seq2seq-Attention_D_iter5400.pt\n",
            "iter : 5400\n",
            " - [input] <SOS> 普通 に 暖かい 家庭 つくろう や 。 何 で 生暖かい 家庭 な ん だ よ 。 <EOS>\n",
            " - [output] も しろ 。 。 も しろ も しろ た 。 だっ たら 流行り 。 あっ なかっ しろ あっ あっ\n",
            " - [gt] <SOS> お父さん お母さん 本当 に 長い 間 お世話 に なり まし た 。 … と 伝え て ください 。 <EOS>\n",
            "Iter:5450, Loss:402.2309, Accu:0.0286\n",
            "Iter:5500, Loss:212.8939, Accu:0.0000\n",
            "Iter:5550, Loss:1244.7432, Accu:0.0000\n",
            "Iter:5600, Loss:448.7594, Accu:0.0441\n",
            "save E >> models/Seq2seq-Attention_E_iter5600.pt, D >> models/Seq2seq-Attention_D_iter5600.pt\n",
            "iter : 5600\n",
            " - [input] <SOS> えっと 、 国内 です よ ね ？ <EOS>\n",
            " - [output] ね もう <EOS> の もう お前 の サラダ なる ね も もう 見 もう\n",
            " - [gt] <SOS> いや 、 ホント は ね 、 海外 行き たい ん だ けど 。 <EOS>\n",
            "Iter:5650, Loss:nan, Accu:0.0000\n",
            "Iter:5700, Loss:nan, Accu:0.0000\n",
            "Iter:5750, Loss:nan, Accu:0.0000\n",
            "Iter:5800, Loss:nan, Accu:0.0000\n",
            "save E >> models/Seq2seq-Attention_E_iter5800.pt, D >> models/Seq2seq-Attention_D_iter5800.pt\n",
            "iter : 5800\n",
            " - [input] <SOS> じゃ 、 戦車 乗っ た こと あり ます ？ <EOS>\n",
            " - [output] 運転 一撃 とこ 街 ちょっかい エース 入れ墨 誠 うるせぇ 1 俺 白 マネジャー きったねー まぁ みんな 薬物 酔っ 聞か お通し かける ユッキー 以下 連絡 伝わっ まあ\n",
            " - [gt] <SOS> ねー よ ！ あっ たら なん な ん だ ！ なぁ ！ また あれ か 、 特攻 の 話 か 、 お前 。 なぁ ！ <EOS>\n",
            "Iter:5850, Loss:nan, Accu:0.0000\n",
            "Iter:5900, Loss:nan, Accu:0.0000\n",
            "Iter:5950, Loss:nan, Accu:0.0000\n",
            "Iter:6000, Loss:nan, Accu:0.0000\n",
            "save E >> models/Seq2seq-Attention_E_iter6000.pt, D >> models/Seq2seq-Attention_D_iter6000.pt\n",
            "iter : 6000\n",
            " - [input] <SOS> まぁ 、 で も もし あれ が プロレス ごっこ だっ たら 、 なん で 高橋 の 制服 だけ 汚れ て 、 お前 の 制服 は 汚れ ない ん だ 。 説明 し て みろ ！ <EOS>\n",
            " - [output] 受ける どれ 4 口 車両 誠 ライス 頂き 自首 とけ 子 しまえ 回 取り ユッキー ほら ウワッ ありがとう 測り\n",
            " - [gt] <SOS> はっ ！ あれ じゃ ねー か な 。 俺 が 強 すぎ ん じゃ ない か な 。 <EOS>\n",
            "Iter:6050, Loss:nan, Accu:0.0000\n",
            "Iter:6100, Loss:nan, Accu:0.0000\n",
            "Iter:6150, Loss:nan, Accu:0.0000\n",
            "Iter:6200, Loss:nan, Accu:0.0000\n",
            "save E >> models/Seq2seq-Attention_E_iter6200.pt, D >> models/Seq2seq-Attention_D_iter6200.pt\n",
            "iter : 6200\n",
            " - [input] <SOS> 毛 の カット 大変 じゃ ない 。 <EOS>\n",
            " - [output] 塾 明け暮れ また もっと 給油 2 せめて 集まり 沖縄 始まん サトルユカリ 体育 へ カード 相談 番組 亡くなっ はは 炎 戦車 面接 向かう ～ 電器 ほう ヤツ サプライズ\n",
            " - [gt] <SOS> 伸び て くる から な 。 トリミング と か 連れ てく ん だ よ 。 正直 ね 俺 の 散髪 より 高い わ 。 ハハハハ 。 <EOS>\n",
            "Iter:6250, Loss:nan, Accu:0.0000\n",
            "Iter:6300, Loss:nan, Accu:0.0000\n",
            "Iter:6350, Loss:nan, Accu:0.0000\n",
            "Iter:6400, Loss:nan, Accu:0.0000\n",
            "save E >> models/Seq2seq-Attention_E_iter6400.pt, D >> models/Seq2seq-Attention_D_iter6400.pt\n",
            "iter : 6400\n",
            " - [input] <SOS> おい 頑張れ コマチ 。 <EOS>\n",
            " - [output] 生 借り は マスコット 25 屈強\n",
            " - [gt] <SOS> お 座り ！ ハウス ！ <EOS>\n",
            "Iter:6450, Loss:nan, Accu:0.0000\n",
            "Iter:6500, Loss:nan, Accu:0.0000\n",
            "Iter:6550, Loss:nan, Accu:0.0000\n",
            "Iter:6600, Loss:nan, Accu:0.0000\n",
            "save E >> models/Seq2seq-Attention_E_iter6600.pt, D >> models/Seq2seq-Attention_D_iter6600.pt\n",
            "iter : 6600\n",
            " - [input] <SOS> 悪い 鬼 を 退治 する 旅 に 出る こと に なっ た 桃太郎 に お じい さん は きりたんぽ を 持た せ まし た <EOS>\n",
            " - [output] とこ たり 現場 夏 家庭 クソ たけなわ お母さん お礼 真っ 帰ら 大変 髪 み サービス サトル みきお 立ちはだかり\n",
            " - [gt] <SOS> きび だんご 持た せ て くれ 、 何 で きりたんぽ あげ た ？ 秋田 出身 か ？ <EOS>\n",
            "Iter:6650, Loss:nan, Accu:0.0000\n",
            "Iter:6700, Loss:nan, Accu:0.0000\n",
            "Iter:6750, Loss:nan, Accu:0.0000\n",
            "Iter:6800, Loss:nan, Accu:0.0000\n",
            "save E >> models/Seq2seq-Attention_E_iter6800.pt, D >> models/Seq2seq-Attention_D_iter6800.pt\n",
            "iter : 6800\n",
            " - [input] <SOS> はい 。 <EOS>\n",
            " - [output] <SOS> 全体 わりー で はは まし かー 負け犬 つか 良かっ\n",
            " - [gt] <SOS> 道しるべ みたい な 。 こう いう やつ ね 。 <EOS>\n",
            "Iter:6850, Loss:nan, Accu:0.0000\n",
            "Iter:6900, Loss:nan, Accu:0.0000\n",
            "Iter:6950, Loss:nan, Accu:0.0000\n",
            "Iter:7000, Loss:nan, Accu:0.0000\n",
            "save E >> models/Seq2seq-Attention_E_iter7000.pt, D >> models/Seq2seq-Attention_D_iter7000.pt\n",
            "iter : 7000\n",
            " - [input] <SOS> 知ら ない ん だ よ お前 の 好き な 漫画 。 俺 の 好き な 漫画 『 クッキングパパ 』 入れ て くれ 。 <EOS>\n",
            " - [output] 洗う いろいろ おかしい 流れ 何故 やかましい\n",
            " - [gt] <SOS> 『 クッキングパパ 』 ね 。 <EOS>\n",
            "Iter:7050, Loss:nan, Accu:0.0000\n",
            "Iter:7100, Loss:nan, Accu:0.0000\n",
            "Iter:7150, Loss:nan, Accu:0.0000\n",
            "Iter:7200, Loss:nan, Accu:0.0000\n",
            "save E >> models/Seq2seq-Attention_E_iter7200.pt, D >> models/Seq2seq-Attention_D_iter7200.pt\n",
            "iter : 7200\n",
            " - [input] <SOS> パチンコ 屋 みてえ に なっ てる わ お前 。 パチンコ 屋 さん みたい だ から なん か 。 「 誠 に 誠 に 」 が パチンコ 屋 な ん だ よ ね 。 「 誠 に 」 1 回 で いい よ 。 <EOS>\n",
            " - [output] 取っ 盗難 耳遠く キャンプ 青い 独特 ませ 日々 カリー えっ ーー 今日 楽 攻撃 ハモっ 皮 れる 盗ん 桃太郎 どんな ウルトラ 全裸\n",
            " - [gt] <SOS> 1 回 で いい ？ 「 私 故 伊達 みきお の 相方 の ザ ・ 富澤 たけし と 申し ます 」 <EOS>\n",
            "Iter:7250, Loss:nan, Accu:0.0000\n",
            "Iter:7300, Loss:nan, Accu:0.0000\n",
            "Iter:7350, Loss:nan, Accu:0.0000\n",
            "Iter:7400, Loss:nan, Accu:0.0000\n",
            "save E >> models/Seq2seq-Attention_E_iter7400.pt, D >> models/Seq2seq-Attention_D_iter7400.pt\n",
            "iter : 7400\n",
            " - [input] <SOS> その まんま 、 静か に 樹海 で 眠っ て もらい ます 。 <EOS>\n",
            " - [output] すげぇ 載っ 戦え トイレ 円 待ち よっ 反省 黒 暇つぶし そん もち 安い 変 流行っ さっき しょうゆ カステラ 本官 渋谷 ば 名前 使用 ガソリン てん\n",
            " - [gt] <SOS> おっかない よ 、 お前 。 永遠 の 眠り に なる わ 、 そんな もん よ 。 帰っ て これ ねー だろ 、 お前 。 <EOS>\n",
            "Iter:7450, Loss:nan, Accu:0.0000\n",
            "Iter:7500, Loss:nan, Accu:0.0000\n",
            "Iter:7550, Loss:nan, Accu:0.0000\n",
            "Iter:7600, Loss:nan, Accu:0.0000\n",
            "save E >> models/Seq2seq-Attention_E_iter7600.pt, D >> models/Seq2seq-Attention_D_iter7600.pt\n",
            "iter : 7600\n",
            " - [input] <SOS> 『 結婚 生活 と は 長い 会話 で ある 』 。 <EOS>\n",
            " - [output] 先立つ ちゃっ えーっと 追い掛け あー 母ちゃん バーン 体形 もし 日\n",
            " - [gt] <SOS> 「 これ は ニーチェ の 言葉 です 」 。 <EOS>\n",
            "Iter:7650, Loss:nan, Accu:0.0000\n",
            "Iter:7700, Loss:nan, Accu:0.0000\n",
            "Iter:7750, Loss:nan, Accu:0.0000\n",
            "Iter:7800, Loss:nan, Accu:0.0000\n",
            "save E >> models/Seq2seq-Attention_E_iter7800.pt, D >> models/Seq2seq-Attention_D_iter7800.pt\n",
            "iter : 7800\n",
            " - [input] <SOS> 予約 割引 も あり ます ん で 。 <EOS>\n",
            " - [output] 万引き 中毒 211 つく 名付け 偽造 決めつけ みんな くじ うるせえ\n",
            " - [gt] <SOS> あ 、 ちょっと 安く も なる ん だ ？ <EOS>\n",
            "Iter:7850, Loss:nan, Accu:0.0000\n",
            "Iter:7900, Loss:nan, Accu:0.0000\n",
            "Iter:7950, Loss:nan, Accu:0.0000\n",
            "Iter:8000, Loss:nan, Accu:0.0000\n",
            "save E >> models/Seq2seq-Attention_E_iter8000.pt, D >> models/Seq2seq-Attention_D_iter8000.pt\n",
            "iter : 8000\n",
            " - [input] <SOS> お前 が 高橋 の 靴 を 隠し てる の 見 た ぞ 。 ああ ？ 鞄 を 持たす とこ も 見 た 。 水 かけ てん の も 見 た 。 ドロップ キック し てん の も 見 た よ ！ <EOS>\n",
            " - [output] 引か 無線 ボディチェック ホント 立派 台 ピカピカ 会場 鳥 かかん 葬儀 ちゃんと 負け 遠く せる ザ 怪しく 聞こえ キンタマ\n",
            " - [gt] <SOS> 結構 見 て ん じゃ ねー か よ ！ 止めろ よ 、 そんな 見 て たら よ 。 <EOS>\n",
            "Iter:8050, Loss:nan, Accu:0.0000\n",
            "Iter:8100, Loss:nan, Accu:0.0000\n",
            "Iter:8150, Loss:nan, Accu:0.0000\n",
            "Iter:8200, Loss:nan, Accu:0.0000\n",
            "save E >> models/Seq2seq-Attention_E_iter8200.pt, D >> models/Seq2seq-Attention_D_iter8200.pt\n",
            "iter : 8200\n",
            " - [input] <SOS> チョコレート ばらまく な 。 何 やっ てん の ？ お前 。 米兵 か 。 <EOS>\n",
            " - [output] 言えよ 世界 ただ\n",
            " - [gt] <SOS> 米兵 ？ <EOS>\n",
            "Iter:8250, Loss:nan, Accu:0.0000\n",
            "Iter:8300, Loss:nan, Accu:0.0000\n",
            "Iter:8350, Loss:nan, Accu:0.0000\n",
            "Iter:8400, Loss:nan, Accu:0.0000\n",
            "save E >> models/Seq2seq-Attention_E_iter8400.pt, D >> models/Seq2seq-Attention_D_iter8400.pt\n",
            "iter : 8400\n",
            " - [input] <SOS> えっと です ねー 。 <EOS>\n",
            " - [output] ヤマアラシ 乙 ５ なきゃ 一番 ジュース 馬鹿 必要 出す 続い 営業 怖い 対する 分から 新宿 楽しかっ ちょっかい 押す ちょいちょい 適度 桃太郎 今年 病気 てめえ 書い あー ライス 文書 流行ん 取る 号 ワキノ ２人 ポンカン サンドウィッチマン 跡 その 人間 全盛 フォーク オーボエ 文句 やかましい 力 がな 潰す\n",
            " - [gt] <SOS> なん で 地球儀 な ん だ よ 、 お前 ！ なん で 地球儀 な ん だ ！ ふざけん な よ 、 お前 ！ 日本 ( にっぽん ) が 見え ねー わ 、 ちっちゃく て よー ！ バカ な ん じゃ ない の 、 お前 。 <EOS>\n",
            "Iter:8450, Loss:nan, Accu:0.0000\n",
            "Iter:8500, Loss:nan, Accu:0.0000\n",
            "Iter:8550, Loss:nan, Accu:0.0000\n",
            "Iter:8600, Loss:nan, Accu:0.0000\n",
            "save E >> models/Seq2seq-Attention_E_iter8600.pt, D >> models/Seq2seq-Attention_D_iter8600.pt\n",
            "iter : 8600\n",
            " - [input] <SOS> やかましい わ 、 お前 。 どっち だ って いい 。 カレー と か カリー と か 。 何 だ それ 、 お前 。 <EOS>\n",
            " - [output] 行かし 応じ 主婦 クソ 洗わ 睡眠 聞い\n",
            " - [gt] <SOS> いや 、 カリー で すっ ！ <EOS>\n",
            "Iter:8650, Loss:nan, Accu:0.0000\n",
            "Iter:8700, Loss:nan, Accu:0.0000\n",
            "Iter:8750, Loss:nan, Accu:0.0000\n",
            "Iter:8800, Loss:nan, Accu:0.0000\n",
            "save E >> models/Seq2seq-Attention_E_iter8800.pt, D >> models/Seq2seq-Attention_D_iter8800.pt\n",
            "iter : 8800\n",
            " - [input] <SOS> 高飛び じゃ ねー よ 、 お前 。 どんな 第一印象 な ん だ よ 。 えぇ ？ 新婚旅行 だ よ 。 <EOS>\n",
            " - [output] コントロール 始まり 豪華 溝 発見 よ 盗難\n",
            " - [gt] <SOS> あ ！ 新婚旅行 です か ！ <EOS>\n",
            "Iter:8850, Loss:nan, Accu:0.0000\n",
            "Iter:8900, Loss:nan, Accu:0.0000\n",
            "Iter:8950, Loss:nan, Accu:0.0000\n",
            "Iter:9000, Loss:nan, Accu:0.0000\n",
            "save E >> models/Seq2seq-Attention_E_iter9000.pt, D >> models/Seq2seq-Attention_D_iter9000.pt\n",
            "iter : 9000\n",
            " - [input] <SOS> あ 、 ホント ！ <EOS>\n",
            " - [output] みたい 映画 ふつう\n",
            " - [gt] <SOS> はい 。 <EOS>\n",
            "Iter:9050, Loss:nan, Accu:0.0000\n",
            "Iter:9100, Loss:nan, Accu:0.0000\n",
            "Iter:9150, Loss:nan, Accu:0.0000\n",
            "Iter:9200, Loss:nan, Accu:0.0000\n",
            "save E >> models/Seq2seq-Attention_E_iter9200.pt, D >> models/Seq2seq-Attention_D_iter9200.pt\n",
            "iter : 9200\n",
            " - [input] <SOS> 駄目 だ よ お前 。 <EOS>\n",
            " - [output] から 全裸 さー 晴天\n",
            " - [gt] <SOS> ドッグフード は ？ <EOS>\n",
            "Iter:9250, Loss:nan, Accu:0.0000\n",
            "Iter:9300, Loss:nan, Accu:0.0000\n",
            "Iter:9350, Loss:nan, Accu:0.0000\n",
            "Iter:9400, Loss:nan, Accu:0.0000\n",
            "save E >> models/Seq2seq-Attention_E_iter9400.pt, D >> models/Seq2seq-Attention_D_iter9400.pt\n",
            "iter : 9400\n",
            " - [input] <SOS> お じい さん が 川 で 洗濯 を し て いる と <EOS>\n",
            " - [output] 茶色 やっ は でき 街 世界 匹 ゼロ つい\n",
            " - [gt] <SOS> 川上 から 大きな 桃 が ドンタコス ったら ドンタコス <EOS>\n",
            "Iter:9450, Loss:nan, Accu:0.0000\n",
            "Iter:9500, Loss:nan, Accu:0.0000\n",
            "Iter:9550, Loss:nan, Accu:0.0000\n",
            "Iter:9600, Loss:nan, Accu:0.0000\n",
            "save E >> models/Seq2seq-Attention_E_iter9600.pt, D >> models/Seq2seq-Attention_D_iter9600.pt\n",
            "iter : 9600\n",
            " - [input] <SOS> いや 、 カリー で すっ ！ <EOS>\n",
            " - [output] おにぎり カード 塩分 与え に れ いっぱい 申し訳 ほっほ 化粧 らしい 現金 猿 国際的 こちら ず ナイフ 円 続い 犬好き エンディング カッコ 堂々 しろ オンエア\n",
            " - [gt] <SOS> どっち だ って いい よ 。 何 だ 「 カリー です 」 って 、 お前 。 流行ん ねー ぞ 、 こんな の よ 。 <EOS>\n",
            "Iter:9650, Loss:nan, Accu:0.0000\n",
            "Iter:9700, Loss:nan, Accu:0.0000\n",
            "Iter:9750, Loss:nan, Accu:0.0000\n",
            "Iter:9800, Loss:nan, Accu:0.0000\n",
            "save E >> models/Seq2seq-Attention_E_iter9800.pt, D >> models/Seq2seq-Attention_D_iter9800.pt\n",
            "iter : 9800\n",
            " - [input] <SOS> リアル だ な 随分 お前 それ 。 <EOS>\n",
            " - [output] 嘘泣き 汚え 引き続き 証明 倫理的 女性 せろ わりー べた 行き 静か 飲み もらおう など はは たって 待っ みんな 来週\n",
            " - [gt] <SOS> 「 腹 の 中 に は 餅米 と 高麗 にんじん を 詰め られ て い まし た 」 <EOS>\n",
            "Iter:9850, Loss:nan, Accu:0.0000\n",
            "Iter:9900, Loss:nan, Accu:0.0000\n",
            "Iter:9950, Loss:nan, Accu:0.0000\n",
            "Iter:10000, Loss:nan, Accu:0.0000\n",
            "save E >> models/Seq2seq-Attention_E_iter10000.pt, D >> models/Seq2seq-Attention_D_iter10000.pt\n",
            "iter : 10000\n",
            " - [input] <SOS> あっ は ！ すい ませ ん 、 お客 さん 。 <EOS>\n",
            " - [output] いれる かわいかっ 警\n",
            " - [gt] <SOS> ああ ？ <EOS>\n",
            "final paramters were saved to E >> models/Seq2seq-Attention_E_final.pt, D >> models/Seq2seq-Attention_D_final.pt\n",
            "loss was saved to >> result/Seq2seq-Attention_loss.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADaElar6khEh",
        "colab_type": "text"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fjit-oNlkhEi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "3ededf17-0601-4068-a923-d3ca97028111"
      },
      "source": [
        "# test\n",
        "def test():\n",
        "    print('-' * 20)\n",
        "    print('test function')\n",
        "    print('-' * 20)\n",
        "    E = Encoder(cfg.CORPUS1_NUM).to(cfg.DEVICE)\n",
        "    D = Decoder(cfg.CORPUS2_NUM).to(cfg.DEVICE)\n",
        "    D.load_state_dict(torch.load(cfg.TEST.MODEL_D_PATH, map_location=torch.device(cfg.DEVICE)))\n",
        "    E.eval()\n",
        "    D.eval()\n",
        "\n",
        "    def generate(sentence):\n",
        "        corpus1 = data_dict['corpus1']\n",
        "        corpus2 = data_dict['corpus2']\n",
        "\n",
        "        Xs = [corpus1.index('<SOS>')]\n",
        "\n",
        "        for word in sentence.split(' '):\n",
        "            if word in corpus1:\n",
        "                Xs.append(corpus1.index(word))\n",
        "            else:\n",
        "                Xs.append(corpus1.index('<UNKNOWN>'))\n",
        "\n",
        "            # encode process\n",
        "            E_hidden = E.initHidden() # initialize encoder hidden\n",
        "            E_outputs = torch.zeros(cfg.SEQ2SEQ_MAX_LENGTH, cfg.SEQ2SEQ_RNN_DIM * (cfg.SEQ2SEQ_USE_RNN_BD + 1)).to(cfg.DEVICE)\n",
        "\n",
        "            for ei in range(xs_length):\n",
        "                E_output, E_hidden = E(Xs[ei], E_hidden, Xs)\n",
        "                E_outputs[ei] = E_output[0, 0]\n",
        "\n",
        "            # decode process\n",
        "            D_xs = ts[0].reshape(1, -1) # define decoder input\n",
        "            D_hidden = E_hidden # define decoder hidden\n",
        "            D_self_memory = D_xs\n",
        "            D_outputs = []\n",
        "\n",
        "            while 1:\n",
        "                # decode\n",
        "                D_ys, D_hidden = D(D_xs, D_hidden, E_outputs, D_self_memory)\n",
        "                \n",
        "                if cfg.SEQ2SEQ_NEXT_WORD_SELECTION == \"argmax\":\n",
        "                    topv, topi = D_ys.data.topk(1)\n",
        "\n",
        "                elif cfg.SEQ2SEQ_NEXT_WORD_SELECTION == \"prob\":\n",
        "                    topi = torch.multinomial(torch.max(D_ys, torch.zeros_like(D_ys) + 1e-5), 1)\n",
        "                \n",
        "                # define next decoder input\n",
        "                if use_teacher:\n",
        "                    D_xs = ts[di] # teacher forcing\n",
        "                else:\n",
        "                    D_xs = topi#.squeeze().detach()\n",
        "\n",
        "                D_xs = D_xs.reshape(1, -1)\n",
        "                D_self_memory = torch.cat([D_self_memory, D_xs])\n",
        "\n",
        "                D_outputs.append(topi.item())\n",
        "\n",
        "                if len(D_outputs) > cfg.SEQ2SEQ_MAX_LENGTH:\n",
        "                    break\n",
        "                if topi.item() == corpus2.index('<EOS>'):\n",
        "                    break\n",
        "\n",
        "            print(' - [input]', ' '.join([corpus1][x] for x in Xs[1:]]))\n",
        "            print(' - [output]', ' '.join([corpus2[x] for x in D_outputs if x not in [0, 1, 2]]))\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for sen in ['I like apple', 'Go ahead', 'Thank you for your nice advice']:\n",
        "            generate(sen)\n",
        "\n",
        "test()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-18-7feebe42f98e>\"\u001b[0;36m, line \u001b[0;32m64\u001b[0m\n\u001b[0;31m    print(' - [input]', ' '.join([corpus1][x] for x in Xs[1:]]))\u001b[0m\n\u001b[0m                                                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xGw8eZAkhEj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def arg_parse():\n",
        "    parser = argparse.ArgumentParser(description='CNN implemented with Keras')\n",
        "    parser.add_argument('--train', dest='train', action='store_true')\n",
        "    parser.add_argument('--test', dest='test', action='store_true')\n",
        "    args = parser.parse_args()\n",
        "    return args\n",
        "\n",
        "# main\n",
        "if __name__ == '__main__':\n",
        "    args = arg_parse()\n",
        "\n",
        "    if args.train:\n",
        "        train()\n",
        "    if args.test:\n",
        "        test()\n",
        "\n",
        "    if not (args.train or args.test):\n",
        "        print(\"please select train or test flag\")\n",
        "        print(\"train: python main.py --train\")\n",
        "        print(\"test:  python main.py --test\")\n",
        "        print(\"both:  python main.py --train --test\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNULcyUAYfZE",
        "colab_type": "text"
      },
      "source": [
        "# dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0yDrCdGB3LJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://arxiv.org/pdf/1606.03777.pdf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VrqdgddB9f1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tarfile\n",
        "\n",
        "tar = tarfile.open(\"icsi_mrda+hs_corpus_050512.tar.gz\", \"r:gz\")\n",
        "for member in tar.getmembers():\n",
        "     f = tar.extractfile(member)\n",
        "     if f is not None:\n",
        "         content = f.read()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdpZjfJsCDyG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "content"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRE_b7PTOlNp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IOq9aG4O0Uc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import zipfile\n",
        "\n",
        "zip_name = 'cornell_movie_dialogs_corpus'\n",
        "\n",
        "with zipfile.ZipFile(zip_name + '.zip') as zf:\n",
        "    names = zf.namelist()\n",
        "    print(names)\n",
        "    zf.extractall(path=zip_name)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnOx4iWZaR5v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dir_name = 'cornell movie-dialogs corpus'\n",
        "\n",
        "with open(dir_name + '/movie_conversations.txt', 'r', encoding='iso-8859-1') as f:\n",
        "    for i, l in enumerate(f.readlines()):\n",
        "        if i > 10:\n",
        "            break\n",
        "        print(l)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7A-8S-BeQXgA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(dir_name + '/movie_lines.txt', 'r', encoding='iso-8859-1') as f:\n",
        "    for i, l in enumerate(f.readlines()):\n",
        "        if i > 10:\n",
        "            break\n",
        "        print(l)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSaFFFFwSk1m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus = []\n",
        "\n",
        "with open(dir_name + '/movie_lines.txt', 'r', encoding='iso-8859-1') as f:\n",
        "    for i, l in enumerate(f.readlines()):\n",
        "        words = l.split(' +++$+++ ')[-1].rstrip('\\n').split(' ')\n",
        "        corpus = list(set(corpus) | set(words))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lcs4XMAVZYS8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aW4IfFqCVjMH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
